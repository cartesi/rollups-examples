# Simple SQLite DApp

This example shows how to build and interact with a minimalistic Cartesi Rollups application that internally runs an [SQLite database](https://www.sqlite.org/index.html). You can send any valid SQL command as input and if it produces results you get those back as a notice.

The example highlights how common mainstream technologies such as an SQL database can be easily used in a Cartesi DApp. It also introduces how errors should be handled by an application, in the case that invalid SQL statements are submitted.

## Building the environment

To run the SQLite example, clone the repository as follows:

```shell
$ git clone https://github.com/cartesi/rollups-examples.git
```

Then, build the back-end for the example:

```shell
$ cd rollups-examples/sqlite
$ make machine
```

## Running the environment

In order to start the containers in production mode, simply run:

```shell
$ docker-compose up --build
```

_Note:_ If you decide to use [Docker Compose V2](https://docs.docker.com/compose/cli-command/), make sure you set the [compatibility flag](https://docs.docker.com/compose/cli-command-compatibility/) when executing the command (e.g., `docker compose --compatibility up`).

Allow some time for the infrastructure to be ready.
How much will depend on your system, but after some time showing the error `"concurrent call in session"`, eventually the container logs will repeatedly show the following:

```shell
server_manager_1      | Received GetVersion
server_manager_1      | Received GetStatus
server_manager_1      |   default_rollups_id
server_manager_1      | Received GetSessionStatus for session default_rollups_id
server_manager_1      |   0
server_manager_1      | Received GetEpochStatus for session default_rollups_id epoch 0
```

To stop the containers, first end the process with `Ctrl + C`.
Then, remove the containers and associated volumes by executing:

```shell
$ docker-compose down -v
```

## Interacting with the application

With the infrastructure in place, you can interact with the application using a set of Hardhat tasks. 

First, go to a separate terminal window, switch to the `echo/contracts` directory, and run `yarn`:

```shell
$ cd sqlite/contracts/
$ yarn
```

Then, send an input as follows to create a table in our DApp's internal database:

```shell
$ npx hardhat --network localhost sqlite:addInput --input "CREATE TABLE Persons (name text, age int)"
```

The input will have been accepted when you receive a response similar to the following one:

```shell
Added input 'CREATE TABLE Persons (name text, age int)' to epoch '0' (index: '0', timestamp: 1640643170, signer: 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266, tx: 0x31d7e9e810d8702196623837b8512097786b544a4b5ffb52f693b9ff7d424147)
```

Next, add an entry to the newly created table by submitting an SQL `INSERT` statement as an input:

```shell
$ npx hardhat --network localhost sqlite:addInput --input "INSERT INTO Persons VALUES ('Peter', 32)"
```

Once data has been inserted into the database, it can be queried using a regular SQL `SELECT` statement such as the following:

```shell
$ npx hardhat --network localhost sqlite:addInput --input "SELECT * FROM Persons"
```

Note that the query's results will not be retrieved immediately. Rather, whenever a submitted input corresponds to a valid SQL query, the DApp will make the corresponding results available in the form of a _notice_.

To verify the notices generated by your query inputs, run a command such as the following:

```shell
$ npx hardhat --network localhost sqlite:getNotices --epoch 0 --payload string
```

The response should be something like this:

```shell
{"session_id":"default_rollups_id","epoch_index":"0","input_index":"2","notice_index":"0","payload":"[[\"Peter\", 32]]"}
```

## Advancing time

To advance time, in order to simulate the passing of epochs, run:

```shell
$ npx hardhat --network localhost util:advanceTime --seconds 864010
```

## Running the environment in host mode

When developing an application, it is often important to easily test and debug it. For that matter, it is possible to run the Cartesi Rollups environment in [host mode](../README.md#host-mode), so that the DApp's back-end can be executed directly on the host machine, allowing it to be debugged using regular development tools such as an IDE.

The first step is to run the environment in host mode using the following command:

```shell
$ docker-compose -f docker-compose.yml -f docker-compose-host.yml up --build
```

The next step is to run the SQLite server in your machine. The application is written in Python, so you need to have `python3` installed.

In order to start the server, run the following commands in a dedicated terminal:

```shell
$ cd sqlite/server/
$ python3 -m venv .env
$ . .env/bin/activate
$ pip install -r requirements.txt
$ HTTP_DISPATCHER_URL="http://127.0.0.1:5004" gunicorn --reload --workers 1 --bind 0.0.0.0:5003 sqlite:app
```

This will run the server on port `5003` and send the corresponding notices to port `5004`. The server will also automatically reload if there is a change in the source code, enabling fast development iterations.

The final command, which effectively starts the server, can also be configured in an IDE to allow interactive debugging using features like breakpoints. In that case, it may be interesting to add the parameter `--timeout 0` to gunicorn, to avoid having it time out when the debugger stops at a breakpoint.

After the server successfully starts, it should print an output like the following:

```
[2022-01-21 12:38:23,971] INFO in sqlite: HTTP dispatcher url is http://127.0.0.1:5004
[2022-01-21 12:38:23 -0500] [79032] [INFO] Starting gunicorn 19.9.0
[2022-01-21 12:38:23 -0500] [79032] [INFO] Listening at: http://0.0.0.0:5003 (79032)
[2022-01-21 12:38:23 -0500] [79032] [INFO] Using worker: sync
[2022-01-21 12:38:23 -0500] [79035] [INFO] Booting worker with pid: 79035
```

After that, you can interact with the application normally [as explained above](#interacting-with-the-application).

When you add an input, you should see it being processed by the server as follows:

```shell
[2022-02-28 20:06:22,314] INFO in sqlite: Received advance request body {'metadata': {'msg_sender': '0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266', 'epoch_index': 0, 'input_index': 9, 'block_number': 20, 'time_stamp': 1646089587}, 'payload': '0x53454c454354202a2046524f4d2074657374'}
[2022-02-28 20:06:22,314] INFO in sqlite: Received statement: SELECT * FROM test
[2022-02-28 20:06:22,315] INFO in sqlite: Adding notice for payload: [["test1", "test2"]]
[2022-02-28 20:06:22,327] INFO in sqlite: Received notice status 201 body b'{"index":0}'
[2022-02-28 20:06:22,328] INFO in sqlite: Finishing
[2022-02-28 20:06:22,339] INFO in sqlite: Received finish status 202
```

Finally, to stop the containers, removing any associated volumes, execute:

```shell
$ docker-compose -f docker-compose.yml -f docker-compose-host.yml down -v
```
