# m2cgen DApp

This example shows a simple way of leveraging some of the most widely used Machine Learning libraries available in Python.

The DApp generates a [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) model using [scikit-learn](https://scikit-learn.org/), [NumPy](https://numpy.org/) and [pandas](https://pandas.pydata.org/), and then uses [m2cgen (Model to Code Generator)](https://github.com/BayesWitnesses/m2cgen) to transpile that model into native Python code with no dependencies. This approach is inspired by [this Machine Learning tutorial](https://www.freecodecamp.org/news/transform-machine-learning-models-into-native-code-with-zero-dependencies/), and is useful for a Cartesi DApp because it removes the need of porting all those Machine Learning libraries to the Cartesi Machine's RISC-V architecture, making the development process easier and the final back-end code simpler to execute.

The practical goal of this application is to predict a classification based on the [Titanic dataset](https://www.kaggle.com/competitions/titanic/data), which shows characteristics of people onboard the Titanic and whether that person survived the disaster or not. As such, users can submit inputs describing a person's features to find out if that person is likely to have survived.

## Building the environment

To run the m2cgen example, clone the repository as follows:

```shell
$ git clone https://github.com/cartesi/rollups-examples.git
```

Then, build the back-end for the m2cgen example:

```shell
$ cd rollups-examples/m2cgen
$ make machine
```

## Running the environment

In order to start the containers in production mode, simply run:

```shell
$ docker-compose up --build
```

_Note:_ If you decide to use [Docker Compose V2](https://docs.docker.com/compose/cli-command/), make sure you set the [compatibility flag](https://docs.docker.com/compose/cli-command-compatibility/) when executing the command (e.g., `docker compose --compatibility up`).

Allow some time for the infrastructure to be ready.
How much will depend on your system, but after some time showing the error `"concurrent call in session"`, eventually the container logs will repeatedly show the following:

```shell
server_manager_1      | Received GetVersion
server_manager_1      | Received GetStatus
server_manager_1      |   default_rollups_id
server_manager_1      | Received GetSessionStatus for session default_rollups_id
server_manager_1      |   0
server_manager_1      | Received GetEpochStatus for session default_rollups_id epoch 0
```

To stop the containers, first end the process with `Ctrl + C`.
Then, remove the containers and associated volumes by executing:

```shell
$ docker-compose down -v
```

## Understanding the application

As explained before, the Titanic dataset used in this application contains only 2 classes: whether a person survived or not the Titanic disaster.

When building the machine, the dataset is used as training data for building a logistic regression model. The model currently takes into account only three characteristics of a person to predict his survival, even though other attributes are available in the dataset:

1. Age
2. Sex, which can be `male` or `female`
3. Embarked, which corresponds to the port of embarkation and can be `C` (Cherbourg), `Q` (Queenstown), or `S` (Southampton)

As such, inputs to the DApp should be given as a JSON string such as the following:
```json
{"Age": 37, "Sex": "male", "Embarked": "S"}
```

The predicted classification result will be given as "0" (did not survive) or "1" (did survive).

## Interacting with the application

With the infrastructure in place, you can interact with the application using a set of Hardhat tasks.

First, go to a separate terminal window, switch to the `m2cgen/contracts` directory, and run `yarn`:

```shell
$ cd m2cgen/contracts/
$ yarn
```

Then, send an input as follows:

```shell
$ npx hardhat --network localhost m2cgen:addInput --input '{"Age": 37, "Sex": "male", "Embarked": "S"}'
```

The input will have been accepted when you receive a response similar to the following one:

```shell
Added input '{"Age": 37, "Sex": "male", "Embarked": "S"}' to epoch '0' (index '0', timestamp: 1640643170, signer: 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266, tx: 0x31d7e9e810d8702196623837b8512097786b544a4b5ffb52f693b9ff7d424147)
```

In order to verify the notices generated by your inputs, run the command:

```shell
$ npx hardhat --network localhost m2cgen:getNotices --epoch 0 --payload string
```

The response should be something like this:

```shell
{"session_id":"default_rollups_id","epoch_index":"0","input_index":"0","notice_index":"0","payload":"0"}
```

Where the payload corresponds to whether the person survived ("1") or not ("0")

## Advancing time

To advance time, in order to simulate the passing of epochs, run:

```shell
$ npx hardhat --network localhost util:advanceTime --seconds 864010
```

## Running the environment in host mode

When developing an application, it is often important to easily test and debug it. For that matter, it is possible to run the Cartesi Rollups environment in [host mode](../README.md#host-mode), so that the DApp's back-end can be executed directly on the host machine, allowing it to be debugged using regular development tools such as an IDE.

The first step is to run the environment in host mode using the following command:

```shell
$ docker-compose -f docker-compose.yml -f docker-compose-host.yml up --build
```

The next step is to run the m2cgen server in your machine. The application is written in Python, so you need to have `python3` installed.

In order to start the m2cgen server, run the following commands in a dedicated terminal:

```shell
$ cd m2cgen/server/
$ python3 -m venv .env
$ . .env/bin/activate
$ pip install -r requirements.txt
$ ROLLUP_HTTP_SERVER_URL="http://127.0.0.1:5004" python3 m2cgen.py
```

This will run the m2cgen server and send the corresponding notices to port `5004`.

The final command, which effectively starts the server, can also be configured in an IDE to allow interactive debugging using features like breakpoints.
You can also use a tool like [entr](https://eradman.com/entrproject/) to restart it automatically when the code changes. For example:

```shell
$ ls *.py | ROLLUP_HTTP_SERVER_URL="http://127.0.0.1:5004" entr -r python3 m2cgen.py
```

After the server successfully starts, it should print an output like the following:

```
INFO:__main__:HTTP rollup_server url is http://127.0.0.1:5004
INFO:__main__:Sending finish
```

After that, you can interact with the application normally [as explained above](#interacting-with-the-application).

When you add an input, you should see it being processed by the m2cgen server as follows:

```log
INFO:__main__:Received finish status 200
INFO:__main__:Received advance request data {'metadata': {'msg_sender': '0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266', 'epoch_index': 0, 'input_index': 0, 'block_number': 0, 'timestamp': 0}, 'payload': '0x7b22416765223a2033372c2022536578223a20226d616c65222c2022456d6261726b6564223a202253227d'}
INFO:__main__:Received input: '{"Age": 37, "Sex": "male", "Embarked": "S"}'
INFO:__main__:Data={"Age": 37, "Sex": "male", "Embarked": "S"}, Predicted: 0
INFO:__main__:Adding notice with payload: 0
INFO:__main__:Received notice status 200 body b'{"index":0}'
INFO:__main__:Sending finish
```

Finally, to stop the containers, removing any associated volumes, execute:

```shell
$ docker-compose -f docker-compose.yml -f docker-compose-host.yml down -v
```

## Changing the application

This DApp was implemented in a rather generic way, and as such it is possible to easily change the target dataset as well as the predictor algorithm.

To change those, open the file `m2cgen/server/model/build_model.py` and change the following variables defined in the beginning of the script:

- `model`: defines the scikit-learn predictor algorithm to use. While it currently uses `sklearn.linear_model.LogisticRegression`, many [other possibilities](https://scikit-learn.org/stable/modules/classes.html) are available, from several types of linear regressions to solutions such as support vector machines (SVMs).
- `train_csv`: a URL or file path to a CSV file containing the dataset. It should contain a first row with the feature names, followed by the data.
- `include`: an optional list indicating a subset of the dataset's features to be used in the prediction model.
- `dependent_var`: the feature to be predicted, such as the entry's classification
